{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J12uLqVTbMEO",
        "outputId": "e2c0a7be-0ddc-4e93-d9c9-578d4ac8e1e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/Business-Quant-Dataset-Html-Tables.zip\"\n",
        "extract_path = \"/content/Business_Quant_Extracted\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas beautifulsoup4 lxml\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Z28e-Rb3Dt",
        "outputId": "3c4e88a8-6337-4908-8a5a-35ef09ec661a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.3.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Define the input folder and output CSV file\n",
        "input_folder = \"Business_Quant_Extracted/Business Quant Dataset - Html Tables\"\n",
        "output_csv = \"extracted_table_data.csv\"\n",
        "\n",
        "data_list = []\n",
        "\n",
        "# Iterate through all extracted HTML files\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.endswith(\".html\"):\n",
        "        file_path = os.path.join(input_folder, file_name)\n",
        "\n",
        "        # Read HTML content\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            html_content = file.read()\n",
        "\n",
        "        # Parse the HTML content using BeautifulSoup\n",
        "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "        # Extract the table title dynamically\n",
        "        table_title = \"-\"\n",
        "        possible_title_tags = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\", \"caption\", \"title\"]\n",
        "        for tag in possible_title_tags:\n",
        "            title_element = soup.find(tag)\n",
        "            if title_element and title_element.text.strip():\n",
        "                table_title = title_element.text.strip()\n",
        "                break  # Stop at the first valid title found\n",
        "\n",
        "        # Ensure the correct title for specific tables\n",
        "        if \"table9\" in file_name.lower() or \"table_9\" in file_name.lower():\n",
        "            table_title = \"Three months ended March 31\"\n",
        "\n",
        "        # Extract tables dynamically\n",
        "        tables = pd.read_html(file_path)\n",
        "\n",
        "        for table in tables:\n",
        "            # Identify the first column as label\n",
        "            label_column = table.columns[0]\n",
        "\n",
        "            # Reshape table into long format\n",
        "            table_melted = table.melt(id_vars=[label_column], var_name=\"column header\", value_name=\"value\")\n",
        "\n",
        "            # Rename first column to \"label\"\n",
        "            table_melted.rename(columns={label_column: \"label\"}, inplace=True)\n",
        "\n",
        "            # Add metadata columns\n",
        "            table_melted.insert(0, \"filename\", file_name.replace(\".html\", \"\"))\n",
        "            table_melted.insert(2, \"tabletitle\", table_title)\n",
        "\n",
        "            # Append to data list\n",
        "            data_list.append(table_melted)\n",
        "\n",
        "# Combine all extracted tables into a single DataFrame\n",
        "final_df = pd.concat(data_list, ignore_index=True)\n",
        "final_df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"Extraction complete! Data saved to {output_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8MhlUGGb508",
        "outputId": "d38ec256-b524-4348-da4f-d44a6a621cda"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete! Data saved to extracted_table_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"extracted_table_data.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "usPRCdUEcBZl",
        "outputId": "9b9eb955-6d23-41d4-d3c3-0ee3907fd664"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2b621802-130e-486b-91f3-702a53c1ec94\", \"extracted_table_data.csv\", 65389)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}